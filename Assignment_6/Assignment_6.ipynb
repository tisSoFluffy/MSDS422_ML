{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "import pydot\n",
    "import datetime\n",
    "from sklearn.ensemble.gradient_boosting import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the Data\n",
    "digit_data = pd.read_csv('train.csv')\n",
    "X_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train,X_val) = train_test_split(digit_data, test_size=.1)\n",
    "y_train = X_train['label']\n",
    "y_val = X_val['label']\n",
    "X_train = X_train.drop('label', axis=1) / 255.0\n",
    "X_val = X_val.drop('label', axis=1) / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(37800, 784)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [0,1,2,3,4,5,6,7,8,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    Flatten(input_shape=[784]),\n",
    "    Dense(300,activation='relu'),\n",
    "    Dense(100,activation='relu'),\n",
    "    Dense(100,activation='relu'),\n",
    "    Dense(100,activation='relu'),\n",
    "    Dense(10,activation='softmax')\n",
    "])\n",
    "model1 = keras.models.Sequential([\n",
    "    Flatten(input_shape=[784]),\n",
    "    Dense(500,activation='relu'),\n",
    "    Dense(1000,activation='relu'),\n",
    "    Dense(300,activation='relu'),\n",
    "    Dense(100,activation='relu'),\n",
    "    Dense(10,activation='softmax')\n",
    "])\n",
    "model2 = keras.models.Sequential([\n",
    "    Flatten(input_shape=[784]),\n",
    "    Dense(500,activation='relu'),\n",
    "    Dense(100,activation='relu'),\n",
    "    Dense(10,activation='softmax')\n",
    "])\n",
    "model3 = keras.models.Sequential([\n",
    "    Flatten(input_shape=[784]),\n",
    "    Dense(300,activation='relu'),\n",
    "    Dense(100,activation='relu'),\n",
    "    Dense(10,activation='softmax')\n",
    "])\n",
    "model4 = keras.models.Sequential([\n",
    "    Flatten(input_shape=[784]),\n",
    "    Dense(1000,activation='relu'),\n",
    "    Dense(100,activation='relu'),\n",
    "    Dense(100,activation='relu'),\n",
    "    Dense(100,activation='relu'),\n",
    "    Dense(10,activation='softmax')\n",
    "])\n",
    "\n",
    "models = [model,model1,model2,model3,model4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nflatten (Flatten)            (None, 784)               0         \n_________________________________________________________________\ndense (Dense)                (None, 300)               235500    \n_________________________________________________________________\ndense_1 (Dense)              (None, 100)               30100     \n_________________________________________________________________\ndense_2 (Dense)              (None, 100)               10100     \n_________________________________________________________________\ndense_3 (Dense)              (None, 100)               10100     \n_________________________________________________________________\ndense_4 (Dense)              (None, 10)                1010      \n=================================================================\nTotal params: 286,810\nTrainable params: 286,810\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Flatten at 0x2d9f8d53580>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x2d9f8b70730>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x2d9f8b70a60>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x2d9f8b70df0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x2d9f8c0f130>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x2d9f8c0f490>]"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'dense'"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "model.layers[1].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, biases = model.layers[1].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 0.05213445, -0.0523987 , -0.05810249, ..., -0.06837106,\n",
       "         0.068583  , -0.05298483],\n",
       "       [ 0.0650496 , -0.04828077,  0.0430701 , ...,  0.04284758,\n",
       "         0.04887644, -0.01396381],\n",
       "       [-0.02699849, -0.04587036, -0.06631325, ..., -0.00626767,\n",
       "        -0.02063423,  0.05234554],\n",
       "       ...,\n",
       "       [ 0.06495905, -0.0165869 , -0.03519252, ..., -0.05269681,\n",
       "         0.05798168, -0.03291587],\n",
       "       [ 0.03256438,  0.00622503, -0.04819008, ..., -0.02715836,\n",
       "         0.05988452,  0.06614803],\n",
       "       [ 0.02775332,  0.00335781, -0.04486591, ...,  0.02074573,\n",
       "         0.05773409, -0.00578506]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(784, 300)"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "biases.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in models:\n",
    "    m.compile(loss='sparse_categorical_crossentropy',\n",
    "        optimizer='sgd',\n",
    "        metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#for m in models:\n",
    "#    m.fit(X_train,y_train,\n",
    "#        epochs=40,\n",
    "#        validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "models[0].history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for m in models:\n",
    "#    print(f'{m} Graph')\n",
    "#    pd.DataFrame(m.history.history).plot(figsize=(8,5))\n",
    "#    plt.grid(True)\n",
    "#    plt.gca().set_ylim(0,1)\n",
    "#    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkpoint_cb = keras.callbacks.ModelCheckpoint('my_keras_model.h5', save_best_only=True)\n",
    "#history = models[4].fit(X_train,y_train, epochs=40, \n",
    "#    validation_split=0.2, callbacks=[checkpoint_cb])\n",
    "#best_model = keras.models.load_model('my_keras_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#pd.DataFrame(digits.history).plot(figsize=(15,5))\n",
    "#plt.grid(True)\n",
    "#plt.gca().set_ylim(0,1)\n",
    "#plt.gca().set_xlim(0,40)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#digits = model.fit(X_train, y_train,\n",
    "#    epochs=40,\n",
    "#    validation_split=0.2)\n",
    "#    \n",
    "#pd.DataFrame(digits.history).plot(figsize=(8,5))\n",
    "#plt.grid(True)\n",
    "#plt.gca().set_ylim(0,1)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_predictions = best_model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_predictions_classes = np.argmax(best_model.predict(test_data), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results = pd.DataFrame(test_predictions_classes)\n",
    "#results.index = np.arange(1, len(results) + 1)\n",
    "#results.to_csv('results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning NN Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to build & compile Keras model, given a set of hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function creates a simple Sequential model for univariate regression using a SGD optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[784], activation='relu'):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=activation))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Kerasregressor based on this build_model() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Evaluate, Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "1182/1182 [==============================] - 1s 726us/step - loss: 3.2537 - val_loss: 2.2197\n",
      "Epoch 2/100\n",
      "1182/1182 [==============================] - 1s 663us/step - loss: 1.8640 - val_loss: 1.6648\n",
      "Epoch 3/100\n",
      "1182/1182 [==============================] - 1s 674us/step - loss: 1.5309 - val_loss: 1.4656\n",
      "Epoch 4/100\n",
      "1182/1182 [==============================] - 1s 702us/step - loss: 1.3721 - val_loss: 1.4534\n",
      "Epoch 5/100\n",
      "1182/1182 [==============================] - 1s 702us/step - loss: 1.2660 - val_loss: 1.3104\n",
      "Epoch 6/100\n",
      "1182/1182 [==============================] - 1s 633us/step - loss: 1.1819 - val_loss: 1.2657\n",
      "Epoch 7/100\n",
      "1182/1182 [==============================] - 1s 608us/step - loss: 1.1191 - val_loss: 1.1823\n",
      "Epoch 8/100\n",
      "1182/1182 [==============================] - 1s 685us/step - loss: 1.0696 - val_loss: 1.2650\n",
      "Epoch 9/100\n",
      "1182/1182 [==============================] - 1s 691us/step - loss: 1.0271 - val_loss: 1.1197\n",
      "Epoch 10/100\n",
      "1182/1182 [==============================] - 1s 659us/step - loss: 0.9919 - val_loss: 1.0994\n",
      "Epoch 11/100\n",
      "1182/1182 [==============================] - 1s 640us/step - loss: 0.9629 - val_loss: 1.0602\n",
      "Epoch 12/100\n",
      "1182/1182 [==============================] - 1s 638us/step - loss: 0.9365 - val_loss: 1.4479\n",
      "Epoch 13/100\n",
      "1182/1182 [==============================] - 1s 613us/step - loss: 0.9181 - val_loss: 1.2688\n",
      "Epoch 14/100\n",
      "1182/1182 [==============================] - 1s 645us/step - loss: 0.8955 - val_loss: 1.0524\n",
      "Epoch 15/100\n",
      "1182/1182 [==============================] - 1s 669us/step - loss: 0.8767 - val_loss: 1.1342\n",
      "Epoch 16/100\n",
      "1182/1182 [==============================] - 1s 653us/step - loss: 0.8675 - val_loss: 1.0201\n",
      "Epoch 17/100\n",
      "1182/1182 [==============================] - 1s 624us/step - loss: 0.8519 - val_loss: 0.9921\n",
      "Epoch 18/100\n",
      "1182/1182 [==============================] - 1s 623us/step - loss: 0.8358 - val_loss: 0.9771\n",
      "Epoch 19/100\n",
      "1182/1182 [==============================] - 1s 676us/step - loss: 0.8275 - val_loss: 0.9699\n",
      "Epoch 20/100\n",
      "1182/1182 [==============================] - 1s 686us/step - loss: 0.8110 - val_loss: 1.2718\n",
      "Epoch 21/100\n",
      "1182/1182 [==============================] - 1s 663us/step - loss: 0.8063 - val_loss: 1.0937\n",
      "Epoch 22/100\n",
      "1182/1182 [==============================] - 1s 665us/step - loss: 0.7933 - val_loss: 1.0213\n",
      "Epoch 23/100\n",
      "1182/1182 [==============================] - 1s 648us/step - loss: 0.7850 - val_loss: 0.9382\n",
      "Epoch 24/100\n",
      "1182/1182 [==============================] - 1s 667us/step - loss: 0.7724 - val_loss: 0.9961\n",
      "Epoch 25/100\n",
      " 625/1182 [==============>...............] - ETA: 0s - loss: 0.7487"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-22b0098d4391>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m keras_reg.fit(X_train, y_train, epochs=100,\n\u001b[0m\u001b[0;32m      2\u001b[0m                 \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                 callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[0mfit_args\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m     \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "keras_reg.fit(X_train, y_train, epochs=100,\n",
    "                validation_data=(X_val,y_val),\n",
    "                callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "263/263 [==============================] - 0s 418us/step - loss: 0.9085\n"
     ]
    }
   ],
   "source": [
    "mse_test = keras_reg.score(X_val, y_val)\n",
    "#y_pred = keras_reg.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Too many hyperparameters, prefer to use a randomized search & not grid search. Explore no. of hidden layers, no. of neurons, & learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "45/100\n",
      "700/700 [==============================] - 1s 752us/step - loss: 0.9271 - val_loss: 1.0947\n",
      "Epoch 46/100\n",
      "700/700 [==============================] - 1s 750us/step - loss: 0.9186 - val_loss: 1.0993\n",
      "Epoch 47/100\n",
      "700/700 [==============================] - 1s 773us/step - loss: 0.9112 - val_loss: 1.0887\n",
      "Epoch 48/100\n",
      "700/700 [==============================] - 1s 757us/step - loss: 0.9059 - val_loss: 1.1053\n",
      "Epoch 49/100\n",
      "700/700 [==============================] - 1s 783us/step - loss: 0.8965 - val_loss: 1.0736\n",
      "Epoch 50/100\n",
      "700/700 [==============================] - 1s 772us/step - loss: 0.8907 - val_loss: 1.0751\n",
      "Epoch 51/100\n",
      "700/700 [==============================] - 1s 752us/step - loss: 0.8852 - val_loss: 1.0773\n",
      "Epoch 52/100\n",
      "700/700 [==============================] - 1s 736us/step - loss: 0.8793 - val_loss: 1.1111\n",
      "Epoch 53/100\n",
      "700/700 [==============================] - 1s 727us/step - loss: 0.8734 - val_loss: 1.0618\n",
      "Epoch 54/100\n",
      "700/700 [==============================] - 1s 747us/step - loss: 0.8658 - val_loss: 1.1322\n",
      "Epoch 55/100\n",
      "700/700 [==============================] - 1s 737us/step - loss: 0.8597 - val_loss: 1.0513\n",
      "Epoch 56/100\n",
      "700/700 [==============================] - 1s 754us/step - loss: 0.8556 - val_loss: 1.0575\n",
      "Epoch 57/100\n",
      "700/700 [==============================] - 1s 740us/step - loss: 0.8509 - val_loss: 1.0516\n",
      "Epoch 58/100\n",
      "700/700 [==============================] - 1s 753us/step - loss: 0.8440 - val_loss: 1.0386\n",
      "Epoch 59/100\n",
      "700/700 [==============================] - 1s 802us/step - loss: 0.8423 - val_loss: 1.0763\n",
      "Epoch 60/100\n",
      "700/700 [==============================] - 1s 739us/step - loss: 0.8335 - val_loss: 1.0452\n",
      "Epoch 61/100\n",
      "700/700 [==============================] - 1s 733us/step - loss: 0.8262 - val_loss: 1.0265\n",
      "Epoch 62/100\n",
      "700/700 [==============================] - 1s 744us/step - loss: 0.8241 - val_loss: 1.0439\n",
      "Epoch 63/100\n",
      "700/700 [==============================] - 1s 739us/step - loss: 0.8223 - val_loss: 1.0245\n",
      "Epoch 64/100\n",
      "700/700 [==============================] - 1s 736us/step - loss: 0.8135 - val_loss: 1.0307\n",
      "Epoch 65/100\n",
      "700/700 [==============================] - 1s 729us/step - loss: 0.8124 - val_loss: 1.0210\n",
      "Epoch 66/100\n",
      "700/700 [==============================] - 1s 719us/step - loss: 0.8095 - val_loss: 1.0250\n",
      "Epoch 67/100\n",
      "700/700 [==============================] - 1s 760us/step - loss: 0.8034 - val_loss: 1.0294\n",
      "Epoch 68/100\n",
      "700/700 [==============================] - 1s 756us/step - loss: 0.7981 - val_loss: 1.0207\n",
      "Epoch 69/100\n",
      "700/700 [==============================] - 1s 747us/step - loss: 0.7966 - val_loss: 1.0176\n",
      "Epoch 70/100\n",
      "700/700 [==============================] - 1s 737us/step - loss: 0.7918 - val_loss: 1.0083\n",
      "Epoch 71/100\n",
      "700/700 [==============================] - 1s 726us/step - loss: 0.7854 - val_loss: 1.0225\n",
      "Epoch 72/100\n",
      "700/700 [==============================] - 1s 736us/step - loss: 0.7818 - val_loss: 1.0431\n",
      "Epoch 73/100\n",
      "700/700 [==============================] - 1s 734us/step - loss: 0.7798 - val_loss: 1.0259\n",
      "Epoch 74/100\n",
      "700/700 [==============================] - 1s 726us/step - loss: 0.7752 - val_loss: 1.0026\n",
      "Epoch 75/100\n",
      "700/700 [==============================] - 1s 746us/step - loss: 0.7686 - val_loss: 1.0037\n",
      "Epoch 76/100\n",
      "700/700 [==============================] - 1s 732us/step - loss: 0.7659 - val_loss: 1.0002\n",
      "Epoch 77/100\n",
      "700/700 [==============================] - 1s 752us/step - loss: 0.7663 - val_loss: 1.0333\n",
      "Epoch 78/100\n",
      "700/700 [==============================] - 1s 796us/step - loss: 0.7567 - val_loss: 0.9971\n",
      "Epoch 79/100\n",
      "700/700 [==============================] - 1s 776us/step - loss: 0.7548 - val_loss: 1.0062\n",
      "Epoch 80/100\n",
      "700/700 [==============================] - 1s 773us/step - loss: 0.7534 - val_loss: 1.0084\n",
      "Epoch 81/100\n",
      "700/700 [==============================] - 1s 779us/step - loss: 0.7468 - val_loss: 1.0215\n",
      "Epoch 82/100\n",
      "700/700 [==============================] - 1s 799us/step - loss: 0.7485 - val_loss: 0.9860\n",
      "Epoch 83/100\n",
      "700/700 [==============================] - 1s 787us/step - loss: 0.7443 - val_loss: 0.9968\n",
      "Epoch 84/100\n",
      "700/700 [==============================] - 1s 782us/step - loss: 0.7379 - val_loss: 0.9909\n",
      "Epoch 85/100\n",
      "700/700 [==============================] - 1s 789us/step - loss: 0.7382 - val_loss: 0.9973\n",
      "Epoch 86/100\n",
      "700/700 [==============================] - 1s 769us/step - loss: 0.7348 - val_loss: 1.0018\n",
      "Epoch 87/100\n",
      "700/700 [==============================] - 1s 839us/step - loss: 0.7310 - val_loss: 0.9808\n",
      "Epoch 88/100\n",
      "700/700 [==============================] - 1s 766us/step - loss: 0.7238 - val_loss: 1.1392\n",
      "Epoch 89/100\n",
      "700/700 [==============================] - 1s 774us/step - loss: 0.7239 - val_loss: 0.9792\n",
      "Epoch 90/100\n",
      "700/700 [==============================] - 1s 735us/step - loss: 0.7239 - val_loss: 0.9884\n",
      "Epoch 91/100\n",
      "700/700 [==============================] - 1s 723us/step - loss: 0.7152 - val_loss: 0.9910\n",
      "Epoch 92/100\n",
      "700/700 [==============================] - 1s 763us/step - loss: 0.7134 - val_loss: 1.0710\n",
      "Epoch 93/100\n",
      "700/700 [==============================] - 1s 807us/step - loss: 0.7109 - val_loss: 0.9769\n",
      "Epoch 94/100\n",
      "700/700 [==============================] - 1s 799us/step - loss: 0.7075 - val_loss: 1.0086\n",
      "Epoch 95/100\n",
      "700/700 [==============================] - 1s 804us/step - loss: 0.7056 - val_loss: 0.9893\n",
      "Epoch 96/100\n",
      "700/700 [==============================] - 1s 837us/step - loss: 0.7059 - val_loss: 1.0049\n",
      "Epoch 97/100\n",
      "700/700 [==============================] - 1s 769us/step - loss: 0.6972 - val_loss: 0.9746\n",
      "Epoch 98/100\n",
      "700/700 [==============================] - 1s 795us/step - loss: 0.6991 - val_loss: 1.0005\n",
      "Epoch 99/100\n",
      "700/700 [==============================] - 1s 779us/step - loss: 0.6969 - val_loss: 1.0886\n",
      "Epoch 100/100\n",
      "700/700 [==============================] - 1s 765us/step - loss: 0.6887 - val_loss: 1.0110\n",
      "350/350 [==============================] - 0s 697us/step - loss: 1.0183\n",
      "Epoch 1/100\n",
      "700/700 [==============================] - 1s 906us/step - loss: 4.0607 - val_loss: 3.2783\n",
      "Epoch 2/100\n",
      "700/700 [==============================] - 1s 737us/step - loss: 3.0180 - val_loss: 2.8121\n",
      "Epoch 3/100\n",
      "700/700 [==============================] - 1s 783us/step - loss: 2.5966 - val_loss: 2.5086\n",
      "Epoch 4/100\n",
      "700/700 [==============================] - 1s 786us/step - loss: 2.3237 - val_loss: 2.2543\n",
      "Epoch 5/100\n",
      "700/700 [==============================] - 1s 760us/step - loss: 2.1356 - val_loss: 2.1010\n",
      "Epoch 6/100\n",
      "700/700 [==============================] - 1s 740us/step - loss: 1.9899 - val_loss: 1.9827\n",
      "Epoch 7/100\n",
      "700/700 [==============================] - 1s 749us/step - loss: 1.8694 - val_loss: 1.8973\n",
      "Epoch 8/100\n",
      "700/700 [==============================] - 1s 750us/step - loss: 1.7723 - val_loss: 1.8068\n",
      "Epoch 9/100\n",
      "700/700 [==============================] - 1s 752us/step - loss: 1.6919 - val_loss: 1.7480\n",
      "Epoch 10/100\n",
      "700/700 [==============================] - 1s 757us/step - loss: 1.6281 - val_loss: 1.6959\n",
      "Epoch 11/100\n",
      "700/700 [==============================] - 1s 810us/step - loss: 1.5701 - val_loss: 1.6250\n",
      "Epoch 12/100\n",
      "700/700 [==============================] - 1s 802us/step - loss: 1.5171 - val_loss: 1.5789\n",
      "Epoch 13/100\n",
      "700/700 [==============================] - 1s 833us/step - loss: 1.4684 - val_loss: 1.5304\n",
      "Epoch 14/100\n",
      "700/700 [==============================] - 1s 876us/step - loss: 1.4240 - val_loss: 1.5031\n",
      "Epoch 15/100\n",
      "700/700 [==============================] - 1s 813us/step - loss: 1.3820 - val_loss: 1.4672\n",
      "Epoch 16/100\n",
      "700/700 [==============================] - 1s 819us/step - loss: 1.3423 - val_loss: 1.4781\n",
      "Epoch 17/100\n",
      "700/700 [==============================] - 1s 766us/step - loss: 1.3104 - val_loss: 1.4190\n",
      "Epoch 18/100\n",
      "700/700 [==============================] - 1s 737us/step - loss: 1.2803 - val_loss: 1.3821\n",
      "Epoch 19/100\n",
      "700/700 [==============================] - 1s 757us/step - loss: 1.2497 - val_loss: 1.3679\n",
      "Epoch 20/100\n",
      "700/700 [==============================] - 1s 750us/step - loss: 1.2249 - val_loss: 1.3331\n",
      "Epoch 21/100\n",
      "700/700 [==============================] - 1s 744us/step - loss: 1.2005 - val_loss: 1.3042\n",
      "Epoch 22/100\n",
      "700/700 [==============================] - 1s 806us/step - loss: 1.1779 - val_loss: 1.3013\n",
      "Epoch 23/100\n",
      "700/700 [==============================] - 1s 732us/step - loss: 1.1565 - val_loss: 1.2669\n",
      "Epoch 24/100\n",
      "700/700 [==============================] - 1s 737us/step - loss: 1.1382 - val_loss: 1.2472\n",
      "Epoch 25/100\n",
      "700/700 [==============================] - 1s 759us/step - loss: 1.1209 - val_loss: 1.2714\n",
      "Epoch 26/100\n",
      "700/700 [==============================] - 1s 763us/step - loss: 1.1034 - val_loss: 1.2335\n",
      "Epoch 27/100\n",
      "700/700 [==============================] - 1s 749us/step - loss: 1.0848 - val_loss: 1.2402\n",
      "Epoch 28/100\n",
      "700/700 [==============================] - 1s 732us/step - loss: 1.0706 - val_loss: 1.2024\n",
      "Epoch 29/100\n",
      "700/700 [==============================] - 1s 760us/step - loss: 1.0570 - val_loss: 1.2423\n",
      "Epoch 30/100\n",
      "700/700 [==============================] - 1s 759us/step - loss: 1.0423 - val_loss: 1.1791\n",
      "Epoch 31/100\n",
      "700/700 [==============================] - 1s 789us/step - loss: 1.0295 - val_loss: 1.1979\n",
      "Epoch 32/100\n",
      "700/700 [==============================] - 1s 776us/step - loss: 1.0192 - val_loss: 1.1665\n",
      "Epoch 33/100\n",
      "700/700 [==============================] - 1s 782us/step - loss: 1.0044 - val_loss: 1.1582\n",
      "Epoch 34/100\n",
      "700/700 [==============================] - 1s 786us/step - loss: 0.9928 - val_loss: 1.1459\n",
      "Epoch 35/100\n",
      "700/700 [==============================] - 1s 786us/step - loss: 0.9811 - val_loss: 1.1545\n",
      "Epoch 36/100\n",
      "700/700 [==============================] - 1s 767us/step - loss: 0.9706 - val_loss: 1.1467\n",
      "Epoch 37/100\n",
      "700/700 [==============================] - 1s 793us/step - loss: 0.9613 - val_loss: 1.1388\n",
      "Epoch 38/100\n",
      "700/700 [==============================] - 1s 797us/step - loss: 0.9511 - val_loss: 1.1241\n",
      "Epoch 39/100\n",
      "700/700 [==============================] - 1s 834us/step - loss: 0.9426 - val_loss: 1.1231\n",
      "Epoch 40/100\n",
      "700/700 [==============================] - 1s 829us/step - loss: 0.9309 - val_loss: 1.1376\n",
      "Epoch 41/100\n",
      "700/700 [==============================] - 1s 812us/step - loss: 0.9228 - val_loss: 1.1471\n",
      "Epoch 42/100\n",
      "700/700 [==============================] - 1s 804us/step - loss: 0.9122 - val_loss: 1.0951\n",
      "Epoch 43/100\n",
      "700/700 [==============================] - 1s 802us/step - loss: 0.9072 - val_loss: 1.0781\n",
      "Epoch 44/100\n",
      "700/700 [==============================] - 1s 799us/step - loss: 0.9010 - val_loss: 1.1603\n",
      "Epoch 45/100\n",
      "700/700 [==============================] - 1s 786us/step - loss: 0.8911 - val_loss: 1.0797\n",
      "Epoch 46/100\n",
      "700/700 [==============================] - 1s 813us/step - loss: 0.8832 - val_loss: 1.0811\n",
      "Epoch 47/100\n",
      "700/700 [==============================] - 1s 802us/step - loss: 0.8753 - val_loss: 1.0703\n",
      "Epoch 48/100\n",
      "700/700 [==============================] - 1s 844us/step - loss: 0.8688 - val_loss: 1.1025\n",
      "Epoch 49/100\n",
      "700/700 [==============================] - 1s 849us/step - loss: 0.8598 - val_loss: 1.0620\n",
      "Epoch 50/100\n",
      "700/700 [==============================] - 1s 777us/step - loss: 0.8535 - val_loss: 1.0576\n",
      "Epoch 51/100\n",
      "700/700 [==============================] - 1s 785us/step - loss: 0.8514 - val_loss: 1.0554\n",
      "Epoch 52/100\n",
      "700/700 [==============================] - 1s 753us/step - loss: 0.8441 - val_loss: 1.0525\n",
      "Epoch 53/100\n",
      "700/700 [==============================] - 1s 757us/step - loss: 0.8343 - val_loss: 1.0986\n",
      "Epoch 54/100\n",
      "700/700 [==============================] - 1s 757us/step - loss: 0.8284 - val_loss: 1.0708\n",
      "Epoch 55/100\n",
      "700/700 [==============================] - 1s 733us/step - loss: 0.8268 - val_loss: 1.0505\n",
      "Epoch 56/100\n",
      "700/700 [==============================] - 1s 759us/step - loss: 0.8193 - val_loss: 1.0495\n",
      "Epoch 57/100\n",
      "700/700 [==============================] - 1s 746us/step - loss: 0.8121 - val_loss: 1.0843\n",
      "Epoch 58/100\n",
      "700/700 [==============================] - 1s 770us/step - loss: 0.8101 - val_loss: 1.0535\n",
      "Epoch 59/100\n",
      "700/700 [==============================] - 1s 739us/step - loss: 0.8084 - val_loss: 1.0214\n",
      "Epoch 60/100\n",
      "700/700 [==============================] - 1s 772us/step - loss: 0.7952 - val_loss: 1.0654\n",
      "Epoch 61/100\n",
      "700/700 [==============================] - 1s 793us/step - loss: 0.7897 - val_loss: 1.0486\n",
      "Epoch 62/100\n",
      "700/700 [==============================] - 1s 760us/step - loss: 0.7921 - val_loss: 1.0209\n",
      "Epoch 63/100\n",
      "700/700 [==============================] - 1s 769us/step - loss: 0.7823 - val_loss: 1.0696\n",
      "Epoch 64/100\n",
      "700/700 [==============================] - 1s 976us/step - loss: 0.7792 - val_loss: 1.0108\n",
      "Epoch 65/100\n",
      "700/700 [==============================] - 1s 939us/step - loss: 0.7761 - val_loss: 1.0235\n",
      "Epoch 66/100\n",
      "700/700 [==============================] - 1s 857us/step - loss: 0.7689 - val_loss: 1.0169\n",
      "Epoch 67/100\n",
      "700/700 [==============================] - 1s 882us/step - loss: 0.7671 - val_loss: 1.0208\n",
      "Epoch 68/100\n",
      "700/700 [==============================] - 1s 860us/step - loss: 0.7600 - val_loss: 1.0055\n",
      "Epoch 69/100\n",
      "700/700 [==============================] - 1s 810us/step - loss: 0.7605 - val_loss: 1.0795\n",
      "Epoch 70/100\n",
      "700/700 [==============================] - 1s 820us/step - loss: 0.7514 - val_loss: 1.0045\n",
      "Epoch 71/100\n",
      "700/700 [==============================] - 1s 862us/step - loss: 0.7480 - val_loss: 1.0079\n",
      "Epoch 72/100\n",
      "700/700 [==============================] - 1s 807us/step - loss: 0.7470 - val_loss: 1.1332\n",
      "Epoch 73/100\n",
      "700/700 [==============================] - 1s 849us/step - loss: 0.7424 - val_loss: 1.0062\n",
      "Epoch 74/100\n",
      "700/700 [==============================] - 1s 892us/step - loss: 0.7423 - val_loss: 0.9945\n",
      "Epoch 75/100\n",
      "700/700 [==============================] - 1s 902us/step - loss: 0.7317 - val_loss: 0.9913\n",
      "Epoch 76/100\n",
      "700/700 [==============================] - 1s 869us/step - loss: 0.7320 - val_loss: 1.0361\n",
      "Epoch 77/100\n",
      "700/700 [==============================] - 1s 873us/step - loss: 0.7273 - val_loss: 1.0121\n",
      "Epoch 78/100\n",
      "700/700 [==============================] - 1s 802us/step - loss: 0.7217 - val_loss: 0.9992\n",
      "Epoch 79/100\n",
      "700/700 [==============================] - 1s 870us/step - loss: 0.7211 - val_loss: 1.0296\n",
      "Epoch 80/100\n",
      "700/700 [==============================] - 1s 872us/step - loss: 0.7161 - val_loss: 1.0308\n",
      "Epoch 81/100\n",
      "700/700 [==============================] - 1s 813us/step - loss: 0.7144 - val_loss: 0.9902\n",
      "Epoch 82/100\n",
      "700/700 [==============================] - 1s 814us/step - loss: 0.7113 - val_loss: 1.0107\n",
      "Epoch 83/100\n",
      "700/700 [==============================] - 1s 842us/step - loss: 0.7028 - val_loss: 0.9947\n",
      "Epoch 84/100\n",
      "700/700 [==============================] - 1s 855us/step - loss: 0.6982 - val_loss: 0.9772\n",
      "Epoch 85/100\n",
      "700/700 [==============================] - 1s 831us/step - loss: 0.6996 - val_loss: 0.9651\n",
      "Epoch 86/100\n",
      "700/700 [==============================] - 1s 879us/step - loss: 0.6980 - val_loss: 1.0142\n",
      "Epoch 87/100\n",
      "700/700 [==============================] - 1s 739us/step - loss: 0.6893 - val_loss: 1.0435\n",
      "Epoch 88/100\n",
      "700/700 [==============================] - 1s 733us/step - loss: 0.6921 - val_loss: 1.0269\n",
      "Epoch 89/100\n",
      "700/700 [==============================] - 1s 776us/step - loss: 0.6854 - val_loss: 0.9703\n",
      "Epoch 90/100\n",
      "700/700 [==============================] - 1s 783us/step - loss: 0.6837 - val_loss: 0.9843\n",
      "Epoch 91/100\n",
      "700/700 [==============================] - 1s 749us/step - loss: 0.6795 - val_loss: 0.9775\n",
      "Epoch 92/100\n",
      "700/700 [==============================] - 1s 763us/step - loss: 0.6777 - val_loss: 0.9581\n",
      "Epoch 93/100\n",
      "700/700 [==============================] - 1s 777us/step - loss: 0.6796 - val_loss: 0.9858\n",
      "Epoch 94/100\n",
      "700/700 [==============================] - 1s 749us/step - loss: 0.6735 - val_loss: 0.9585\n",
      "Epoch 95/100\n",
      "700/700 [==============================] - 1s 736us/step - loss: 0.6675 - val_loss: 0.9497\n",
      "Epoch 96/100\n",
      "700/700 [==============================] - 0s 702us/step - loss: 0.6676 - val_loss: 0.9706\n",
      "Epoch 97/100\n",
      "700/700 [==============================] - 0s 702us/step - loss: 0.6689 - val_loss: 0.9795\n",
      "Epoch 98/100\n",
      "700/700 [==============================] - 0s 713us/step - loss: 0.6584 - val_loss: 0.9838\n",
      "Epoch 99/100\n",
      "700/700 [==============================] - 0s 712us/step - loss: 0.6575 - val_loss: 0.9541\n",
      "Epoch 100/100\n",
      "700/700 [==============================] - 0s 702us/step - loss: 0.6581 - val_loss: 0.9617\n",
      "350/350 [==============================] - 0s 646us/step - loss: 0.9705\n",
      "Epoch 1/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: 3.3371 - val_loss: 2.4010\n",
      "Epoch 2/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: 2.1499 - val_loss: 1.8401\n",
      "Epoch 3/100\n",
      "700/700 [==============================] - 1s 993us/step - loss: 1.6835 - val_loss: 1.5554\n",
      "Epoch 4/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: 1.4539 - val_loss: 1.4034\n",
      "Epoch 5/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: 1.2975 - val_loss: 1.4965\n",
      "Epoch 6/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: 1.1873 - val_loss: 1.1946\n",
      "Epoch 7/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: 1.1019 - val_loss: 1.2199\n",
      "Epoch 8/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: 1.0384 - val_loss: 1.0857\n",
      "Epoch 9/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: 0.9866 - val_loss: 1.1426\n",
      "Epoch 10/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: 0.9478 - val_loss: 1.0632\n",
      "Epoch 11/100\n",
      "700/700 [==============================] - 1s 999us/step - loss: 0.9031 - val_loss: 0.9710\n",
      "Epoch 12/100\n",
      "700/700 [==============================] - 1s 989us/step - loss: 0.8674 - val_loss: 0.9781\n",
      "Epoch 13/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: 0.8398 - val_loss: 0.9429\n",
      "Epoch 14/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: 0.8086 - val_loss: 0.9363\n",
      "Epoch 15/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: 0.7882 - val_loss: 0.9212\n",
      "Epoch 16/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: 0.7631 - val_loss: 0.9545\n",
      "Epoch 17/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: 0.7516 - val_loss: 0.9397\n",
      "Epoch 18/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: 0.7250 - val_loss: 0.8850\n",
      "Epoch 19/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: 0.7066 - val_loss: 1.0507\n",
      "Epoch 20/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: 0.6881 - val_loss: 0.8532\n",
      "Epoch 21/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: 0.6735 - val_loss: 1.0373\n",
      "Epoch 22/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: 0.6578 - val_loss: 0.8275\n",
      "Epoch 23/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: 0.6463 - val_loss: 0.8360\n",
      "Epoch 24/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: 0.6314 - val_loss: 0.8198\n",
      "Epoch 25/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: 0.6176 - val_loss: 0.8440\n",
      "Epoch 26/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: 0.6080 - val_loss: 0.8365\n",
      "Epoch 27/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: 0.5944 - val_loss: 0.8227\n",
      "Epoch 28/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: 0.5849 - val_loss: 0.8087\n",
      "Epoch 29/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: 0.5721 - val_loss: 0.8525\n",
      "Epoch 30/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: 0.5671 - val_loss: 0.7802\n",
      "Epoch 31/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: 0.5501 - val_loss: 0.7973\n",
      "Epoch 32/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: 0.5438 - val_loss: 0.7733\n",
      "Epoch 33/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: 0.5409 - val_loss: 0.7883\n",
      "Epoch 34/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: 0.5283 - val_loss: 0.8061\n",
      "Epoch 35/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: 0.5173 - val_loss: 0.7649\n",
      "Epoch 36/100\n",
      " 59/700 [=>............................] - ETA: 0s - loss: 0.4611"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-aa5e2734673a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mrnd_serach_cv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras_reg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_distribs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m rnd_serach_cv.fit(X_train, y_train,\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     validation_data = (X_val, y_val),callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    734\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1527\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1528\u001b[0m         \u001b[1;34m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1529\u001b[1;33m         evaluate_candidates(ParameterSampler(\n\u001b[0m\u001b[0;32m   1530\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1531\u001b[0m             random_state=self.random_state))\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    706\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 708\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    709\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1032\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1033\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    845\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    846\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 847\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    848\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    763\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    253\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    253\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    529\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[0mfit_args\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m     \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "param_distribs = {\n",
    "    \"n_hidden\": [0, 1, 2, 3],\n",
    "    \"n_neurons\": np.arange(1,100),\n",
    "    \"learning_rate\": reciprocal(3e-4, 3e-2),\n",
    "}\n",
    "\n",
    "rnd_serach_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter = 10, cv = 3)\n",
    "rnd_serach_cv.fit(X_train, y_train,\n",
    "    epochs = 100,\n",
    "    validation_data = (X_val, y_val),callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "root_logdir = os.path.join(os.curdir, 'my_logs')\n",
    "\n",
    "def get_run_logdir():\n",
    "    run_id = time.strftime('run_%Y_%m_%d-%H_%M_%S')\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "   2/1050 [..............................] - ETA: 3:29 - loss: 17.7337WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.3981s). Check your callbacks.\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 2.5677 - val_loss: 1.6796\n",
      "Epoch 2/100\n",
      "1050/1050 [==============================] - 1s 727us/step - loss: 1.5341 - val_loss: 1.4073\n",
      "Epoch 3/100\n",
      "1050/1050 [==============================] - 1s 728us/step - loss: 1.3197 - val_loss: 1.3232\n",
      "Epoch 4/100\n",
      "1050/1050 [==============================] - 1s 734us/step - loss: 1.2080 - val_loss: 1.1901\n",
      "Epoch 5/100\n",
      "1050/1050 [==============================] - 1s 720us/step - loss: 1.1326 - val_loss: 1.1360\n",
      "Epoch 6/100\n",
      "1050/1050 [==============================] - 1s 703us/step - loss: 1.0830 - val_loss: 1.2180\n",
      "Epoch 7/100\n",
      "1050/1050 [==============================] - 1s 681us/step - loss: 1.0499 - val_loss: 1.1357\n",
      "Epoch 8/100\n",
      "1050/1050 [==============================] - 1s 680us/step - loss: 1.0085 - val_loss: 1.1612\n",
      "Epoch 9/100\n",
      "1050/1050 [==============================] - 1s 704us/step - loss: 0.9762 - val_loss: 1.1138\n",
      "Epoch 10/100\n",
      "1050/1050 [==============================] - 1s 704us/step - loss: 0.9612 - val_loss: 1.0696\n",
      "Epoch 11/100\n",
      "1050/1050 [==============================] - 1s 711us/step - loss: 0.9375 - val_loss: 1.0477\n",
      "Epoch 12/100\n",
      "1050/1050 [==============================] - 1s 759us/step - loss: 0.9147 - val_loss: 1.0533\n",
      "Epoch 13/100\n",
      "1050/1050 [==============================] - 1s 728us/step - loss: 0.8994 - val_loss: 1.0186\n",
      "Epoch 14/100\n",
      "1050/1050 [==============================] - 1s 751us/step - loss: 0.8875 - val_loss: 1.0064\n",
      "Epoch 15/100\n",
      "1050/1050 [==============================] - 1s 728us/step - loss: 0.8751 - val_loss: 1.0187\n",
      "Epoch 16/100\n",
      "1050/1050 [==============================] - 1s 703us/step - loss: 0.8683 - val_loss: 1.0074\n",
      "Epoch 17/100\n",
      "1050/1050 [==============================] - 1s 719us/step - loss: 0.8516 - val_loss: 1.0714\n",
      "Epoch 18/100\n",
      "1050/1050 [==============================] - 1s 743us/step - loss: 0.8470 - val_loss: 0.9908\n",
      "Epoch 19/100\n",
      "1050/1050 [==============================] - 1s 729us/step - loss: 0.8332 - val_loss: 1.0259\n",
      "Epoch 20/100\n",
      "1050/1050 [==============================] - 2s 1ms/step - loss: 0.8247 - val_loss: 1.0320\n",
      "Epoch 21/100\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.8110 - val_loss: 1.0711\n",
      "Epoch 22/100\n",
      "1050/1050 [==============================] - 1s 964us/step - loss: 0.8043 - val_loss: 1.0892\n",
      "Epoch 23/100\n",
      "1050/1050 [==============================] - 1s 989us/step - loss: 0.7961 - val_loss: 1.0316\n",
      "Epoch 24/100\n",
      "1050/1050 [==============================] - 1s 918us/step - loss: 0.7890 - val_loss: 0.9807\n",
      "Epoch 25/100\n",
      "1050/1050 [==============================] - 1s 925us/step - loss: 0.7822 - val_loss: 0.9647\n",
      "Epoch 26/100\n",
      "1050/1050 [==============================] - 1s 957us/step - loss: 0.7811 - val_loss: 0.9606\n",
      "Epoch 27/100\n",
      "1050/1050 [==============================] - 1s 934us/step - loss: 0.7782 - val_loss: 0.9866\n",
      "Epoch 28/100\n",
      "1050/1050 [==============================] - 1s 909us/step - loss: 0.7692 - val_loss: 1.0310\n",
      "Epoch 29/100\n",
      "1050/1050 [==============================] - 1s 884us/step - loss: 0.7673 - val_loss: 0.9671\n",
      "Epoch 30/100\n",
      "1050/1050 [==============================] - 1s 865us/step - loss: 0.7539 - val_loss: 1.1530\n",
      "Epoch 31/100\n",
      "1050/1050 [==============================] - 2s 1ms/step - loss: 0.7557 - val_loss: 0.9828\n",
      "Epoch 32/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.7482 - val_loss: 0.9403\n",
      "Epoch 33/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.7397 - val_loss: 0.9526\n",
      "Epoch 34/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.7406 - val_loss: 0.9742\n",
      "Epoch 35/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.7312 - val_loss: 0.9829\n",
      "Epoch 36/100\n",
      "1050/1050 [==============================] - 1s 676us/step - loss: 0.7300 - val_loss: 0.9714\n",
      "Epoch 37/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.7260 - val_loss: 0.9722\n",
      "Epoch 38/100\n",
      "1050/1050 [==============================] - 1s 694us/step - loss: 0.7221 - val_loss: 0.9394\n",
      "Epoch 39/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.7190 - val_loss: 0.9318\n",
      "Epoch 40/100\n",
      "1050/1050 [==============================] - 1s 639us/step - loss: 0.7136 - val_loss: 0.9448\n",
      "Epoch 41/100\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.7110 - val_loss: 0.9567\n",
      "Epoch 42/100\n",
      "1050/1050 [==============================] - 1s 649us/step - loss: 0.7059 - val_loss: 1.0195\n",
      "Epoch 43/100\n",
      "1050/1050 [==============================] - 1s 648us/step - loss: 0.7079 - val_loss: 1.0842\n",
      "Epoch 44/100\n",
      "1050/1050 [==============================] - 1s 835us/step - loss: 0.7030 - val_loss: 0.9973\n",
      "Epoch 45/100\n",
      "1050/1050 [==============================] - 1s 636us/step - loss: 0.7024 - val_loss: 0.9411\n",
      "Epoch 46/100\n",
      "1050/1050 [==============================] - 1s 640us/step - loss: 0.6973 - val_loss: 0.9189\n",
      "Epoch 47/100\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.6977 - val_loss: 0.9480\n",
      "Epoch 48/100\n",
      "1050/1050 [==============================] - 1s 688us/step - loss: 0.6845 - val_loss: 0.9508\n",
      "Epoch 49/100\n",
      "1050/1050 [==============================] - 1s 695us/step - loss: 0.6864 - val_loss: 0.9712\n",
      "Epoch 50/100\n",
      "1050/1050 [==============================] - 1s 704us/step - loss: 0.6806 - val_loss: 1.0060\n",
      "Epoch 51/100\n",
      "1050/1050 [==============================] - 1s 704us/step - loss: 0.6799 - val_loss: 1.0363\n",
      "Epoch 52/100\n",
      "1050/1050 [==============================] - 1s 713us/step - loss: 0.6831 - val_loss: 1.1182\n",
      "Epoch 53/100\n",
      "1050/1050 [==============================] - 1s 718us/step - loss: 0.6767 - val_loss: 1.0143\n",
      "Epoch 54/100\n",
      "1050/1050 [==============================] - 1s 713us/step - loss: 0.6766 - val_loss: 0.9340\n",
      "Epoch 55/100\n",
      "1050/1050 [==============================] - 1s 688us/step - loss: 0.6754 - val_loss: 0.9887\n",
      "Epoch 56/100\n",
      "1050/1050 [==============================] - 1s 665us/step - loss: 0.6717 - val_loss: 1.0294\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "#TODO add best param model here\n",
    "history = keras_reg.fit(X_train,y_train,\n",
    "    epochs=100,\n",
    "    validation_data=(X_val,y_val),\n",
    "    callbacks=[tensorboard_cb, keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([2.6644855, 0.2920136, 8.155593 , ..., 2.8528655, 9.187014 ,\n",
       "       1.3953745], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "source": [
    "keras_reg.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}